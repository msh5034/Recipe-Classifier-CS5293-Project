{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration For Recipe Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is for a class project, and not the Kaggle \"What's Cooking\" competition, the goals are a little different. While accuracy is important, since this is based on the fictional scenario of \"ingredients on hand\", there won't be exactly right and wrong answers. A model that trains and predicts quickly would be valuable here, so that the model would not need to be stored anywhere, and a model that has a method to predict the most similar recipes to the input would make things simpler (looking at you, kNN). Additionally, since a required output is some sort of \"similarity\" or \"probability\" to the predicted cuisine, a classifier with a predict_proba() function would be desirable.\n",
    "\n",
    "To achieve this, I'm going to look at a few different ways to vectorize the data (along with some basic \"cleaning\" of the recipes), and then test the data with different models and different sets of hyperparameters. Since speed is valuable here as well, I'll also be looking at which models perform well with smaller fractions of the dataset. cross_val_score with the accuracy metric from sklearn will be used to assess each model. Since the \"test\" here is with user input data, 100% of the data will be used for training/cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pandas .read_json() functionality to simplify reading in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'yummly.json'\n",
    "df = pd.read_json(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De-Tokenize for Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaning and some vectorization works better when all of the data is joined together, so a column is added to the dataframe with the joined recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_tokenize(df):\n",
    "    '''\n",
    "    takes a dataframe as argument\n",
    "    returns same dataframe with additional column for joined ingredient lists\n",
    "    '''\n",
    "    \n",
    "    l = [' '.join(recipe) for recipe in df['ingredients']] #get list of joined ingredient lists\n",
    "    \n",
    "    df['ing_join'] = l #create new column in dataframe to hold them\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = de_tokenize(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove some stopwords, and do some basic cleaning. Since word2vec likes the tokenized recipes, while the other vectorizers like the joined recipes, the functions will add both tokenized and non-tokenized columns to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text,stopwords):\n",
    "    '''\n",
    "    Takes text and a set of stopwords as arguments and returns word tokens without stopwords\n",
    "    '''\n",
    "    \n",
    "    tokens = word_tokenize(text) #tokenize the words in the recipe\n",
    "    cleaned_tokens = [word for word in tokens if word not in stopwords] #remove stopwords\n",
    "    \n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_recipes(df):\n",
    "    \n",
    "    '''\n",
    "    takes the recipe dataframe as an argument\n",
    "    removes stopwords, does basic cleaning and adds cleaned columns to dataframe\n",
    "    '''\n",
    "    \n",
    "    stops = set(stopwords.words('english')) #get stopwords\n",
    "    tokl = [] #initialize tokenized recipes list\n",
    "    sentl = [] #initialize joined list\n",
    "    \n",
    "    for sent in df['ing_join']:\n",
    "        \n",
    "        sent.replace('mayonnais','mayonnaise') #a bunch of recipes have mayonnaise misspelled for some reason\n",
    "    \n",
    "        sent=re.sub(r'\\([^)]*\\)', '', sent) #remove parentheticals\n",
    "    \n",
    "        sent=re.sub(r'[^a-zA-Z ]+','',sent) #remove punctuation and numbers\n",
    "    \n",
    "        sent=sent.lower() #convert to lowercase\n",
    "    \n",
    "        tok=remove_stopwords(sent,stops) #get stopword-free tokens\n",
    "        \n",
    "        tokl.append(tok) #append to the tokenized list\n",
    "        \n",
    "        sent=' '.join(tok) #get joined sentence\n",
    "        \n",
    "        sentl.append(sent) #append to sentence list\n",
    "    \n",
    "    df['ing_clean']=sentl #add column to df\n",
    "    df['ing_clean_tok'] = tokl #add column to df\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_recipes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results of cleaning. Notice that the cleaned tokenized recipes are tokenized differently than the non-cleaned tokenized recipes. Will check to see if this makes a difference experimentally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ing_join</th>\n",
       "      <th>ing_clean</th>\n",
       "      <th>ing_clean_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>romaine lettuce black olives grape tomatoes ga...</td>\n",
       "      <td>romaine lettuce black olives grape tomatoes ga...</td>\n",
       "      <td>[romaine, lettuce, black, olives, grape, tomat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>plain flour ground pepper salt tomatoes ground...</td>\n",
       "      <td>plain flour ground pepper salt tomatoes ground...</td>\n",
       "      <td>[plain, flour, ground, pepper, salt, tomatoes,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>eggs pepper salt mayonaise cooking oil green c...</td>\n",
       "      <td>eggs pepper salt mayonaise cooking oil green c...</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking, oil, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "      <td>[water, vegetable, oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>black pepper shallots cornflour cayenne pepper...</td>\n",
       "      <td>black pepper shallots cornflour cayenne pepper...</td>\n",
       "      <td>[black, pepper, shallots, cornflour, cayenne, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]   \n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "                                            ing_join  \\\n",
       "0  romaine lettuce black olives grape tomatoes ga...   \n",
       "1  plain flour ground pepper salt tomatoes ground...   \n",
       "2  eggs pepper salt mayonaise cooking oil green c...   \n",
       "3                     water vegetable oil wheat salt   \n",
       "4  black pepper shallots cornflour cayenne pepper...   \n",
       "\n",
       "                                           ing_clean  \\\n",
       "0  romaine lettuce black olives grape tomatoes ga...   \n",
       "1  plain flour ground pepper salt tomatoes ground...   \n",
       "2  eggs pepper salt mayonaise cooking oil green c...   \n",
       "3                     water vegetable oil wheat salt   \n",
       "4  black pepper shallots cornflour cayenne pepper...   \n",
       "\n",
       "                                       ing_clean_tok  \n",
       "0  [romaine, lettuce, black, olives, grape, tomat...  \n",
       "1  [plain, flour, ground, pepper, salt, tomatoes,...  \n",
       "2  [eggs, pepper, salt, mayonaise, cooking, oil, ...  \n",
       "3               [water, vegetable, oil, wheat, salt]  \n",
       "4  [black, pepper, shallots, cornflour, cayenne, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Recipes\n",
    "In this section, the recipe ingredients will be vectorized using CountVectorizer, TfidfVectorizer, Word2Vec (from gensim) and GloVe (from SpaCy). Both the cleaned and uncleaned versions of the recipes will be vectorized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 2475)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_cvec = CountVectorizer(min_df=2) #tried to capture as many ingredients as possible while filtering for typos\n",
    "clean_cmat = clean_cvec.fit_transform(df['ing_clean']) #vectorize the cleaned versions of recipes\n",
    "clean_cmat.shape #check shape of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 2459)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirt_cvec = CountVectorizer(min_df=2) #tried to capture as many ingredients as possible while filtering for typos\n",
    "dirt_cmat = dirt_cvec.fit_transform(df['ing_join']) #vectorized the un-cleaned versions of recipes\n",
    "dirt_cmat.shape #check shape of matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 2475)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_vec = TfidfVectorizer(min_df=2) #tried to capture as many ingredients as possible while filtering for typos\n",
    "clean_mat = clean_vec.fit_transform(df['ing_clean']) #vectorize the cleaned versions of recipes\n",
    "clean_mat.shape #check shape of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 2459)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirt_vec = TfidfVectorizer(min_df=2) #tried to capture as many ingredients as possible while filtering for typos\n",
    "dirt_mat = dirt_vec.fit_transform(df['ing_join']) #vectorized the un-cleaned versions of recipes\n",
    "dirt_mat.shape #check shape of matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(df, size=300, mincount=2, clean=False):\n",
    "    \n",
    "    '''\n",
    "    takes the recipe dataframe along with some word2vec parameters as arguments\n",
    "    returns the vectors of a trained word2vec model\n",
    "    '''\n",
    "    \n",
    "    if clean:\n",
    "        model = Word2Vec(np.array(df['ing_clean_tok']), size=size, min_count=mincount)\n",
    "    else:\n",
    "        model = Word2Vec(np.array(df['ingredients']), size=size, min_count=mincount)\n",
    "    \n",
    "    return model.wv #returning the .wv portion (i.e. just vectors) of the model saves memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe_vectors(df,mod_vecs,zeros=False, clean=False):\n",
    "    \n",
    "    '''\n",
    "    takes the recipe dataframe and word2vec vectors as arguments\n",
    "    returns the vectorized recipe list\n",
    "    '''\n",
    "\n",
    "    if clean: #determining which column to use for vectorization\n",
    "        \n",
    "        ingredients = np.array(df['ing_clean_tok']) #get the ingredients to vectorize\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        ingredients = np.array(df['ingredients']) #get the ingredients to vectorize\n",
    "    \n",
    "    if zeros: #i.e. any non-found ingredient is given a vector of all zeroes\n",
    "        \n",
    "        length = mod_vecs.vectors.shape[1] #get length of potential zeroes vectors\n",
    "        \n",
    "        vectors = np.array([np.mean([mod_vecs[word] if word in mod_vecs.index2word else np.zeros(length) for word in recipe], \n",
    "                                axis=0) for recipe in ingredients])\n",
    "        #average all of the individual ingredient vectors, so that each recipe has one vector\n",
    "    \n",
    "    else: #i.e. ignore any non-found ingredients\n",
    "        vectors = np.array([np.mean([mod_vecs[word] for word in recipe if word in mod_vecs.index2word], \n",
    "                                    axis=0) for recipe in ingredients])\n",
    "        #average all of the individual ingredient vectors, so that each recipe has one vector\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_mod = get_model(df, clean=True) #get model vectors for cleaned recipes\n",
    "clean_w2vs = get_recipe_vectors(df,clean_mod, zeros=True, clean=True) #get recipe vectors\n",
    "clean_w2vs.shape #check shape of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirt_mod = get_model(df, clean=False) #get model vectors for un-cleaned recipes\n",
    "dirt_w2vs = get_recipe_vectors(df,dirt_mod, zeros=True, clean=False) #get recipe vectors\n",
    "dirt_w2vs.shape #check shape of matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg') #load spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39774, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time dirt_spacy = np.array([nlp(recipe).vector for recipe in df['ing_join']]) #get pre-trained GloVe vectors \n",
    "dirt_spacy.shape #check matrix shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39774, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clean_spacy = np.array([nlp(recipe).vector for recipe in df['ing_clean']]) #get pre-trained GloVe vectors \n",
    "clean_spacy.shape #check matrix shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of speed, the SpaCy vectorization is already pretty slow, being the only vectorization to take more than a minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best Model/Data Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Models\n",
    "Test a few different classification models, with a few different hyperparameter settings. If any model looks particularly promising, further hyperparameter tuning can be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn5 = KNeighborsClassifier()\n",
    "knn10 = KNeighborsClassifier(n_neighbors=10)\n",
    "svc1 = LinearSVC(max_iter=2500)\n",
    "svc05 = LinearSVC(C=0.5, max_iter=2500)\n",
    "logreg1 = LogisticRegression(max_iter=1500)\n",
    "logreg05 = LogisticRegression(C=0.5,max_iter=1500)\n",
    "etree200 = ExtraTreesClassifier(n_estimators=200)\n",
    "rfor200 = RandomForestClassifier(n_estimators=200)\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dictionaries for Models and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'KNN-5': knn5, 'KNN-10': knn10, 'SVC-1': svc1, 'SVC-0.5': svc05, 'LogReg-1': logreg1, 'LogReg-0.5': logreg05,\n",
    "          'ExTrees': etree200, 'RandomForest': rfor200, 'BernoulliNB': bnb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'CleanCountVec': clean_cmat, 'DirtyCountVec': dirt_cmat, 'CleanTfIdf': clean_mat, 'DirtyTfIdf': dirt_mat, \n",
    "        'CleanW2V':clean_w2vs, 'DirtyW2V': dirt_w2vs, 'CleanSpaCy': clean_spacy, 'DirtySpaCy': dirt_spacy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Function for Analysis\n",
    "This will return dataframes that for each combination of model and data formulation store the result of 5-fold cross-validation, and the time it took to perform said cross-validation. Since time is merely an issue of user experience here, and we aren't tryig to squeeze every iota of performance out, the wall-clock time suffices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach_analyzer(models, data, y, pickle=True, verbose=False, accname='', timename=''):\n",
    "    \n",
    "    '''\n",
    "    accepts dictionaries of models and data, along with classification labels, flags and filenames if writing to pickle\n",
    "    cross validates all models using all data formats, storing accuracy scores and runtimes\n",
    "    returns dataframes with the accuracy scores and runtimes of all model-data combinations\n",
    "    '''\n",
    "    \n",
    "    acc_dict = {} #initialize dictionaries to hold accuracy and time data\n",
    "    time_dict = {}\n",
    "    for model in models: #iterate through model dictionaries\n",
    "        \n",
    "        mod = models[model] #get model\n",
    "        \n",
    "        mod_acc_dict = {} #initialize accuracy and time dictionaries for selected model\n",
    "        mod_time_dict = {}\n",
    "        \n",
    "        for datum in data: #iterate through each data formulation\n",
    "            \n",
    "            dat = data[datum] #get vectors\n",
    "            start = time.time() #timestamp\n",
    "            x = cross_val_score(mod, dat, y, cv=5, scoring='accuracy').mean() #cross-validate\n",
    "            mod_acc_dict[datum] = x #store mean cv accuracy score\n",
    "            \n",
    "            elapse = time.time() - start #get elapsed time\n",
    "            \n",
    "            mod_time_dict[datum] = round(elapse,1) #store elapsed time\n",
    "            \n",
    "            if verbose: #print result of cross-validation\n",
    "                print(f'{model} with {datum} data has acc score of {x} and took {round(elapse/60,1)} minutes to cross-validate')\n",
    "        \n",
    "        acc_dict[model] = mod_acc_dict #insert model dictionaries into general dictionaries\n",
    "        time_dict[model] = mod_time_dict\n",
    "    \n",
    "    df_acc = pd.DataFrame(acc_dict) #create dataframes from dictionaries\n",
    "    df_time = pd.DataFrame(time_dict)\n",
    "    \n",
    "    if pickle: #optionally store results in pickles due to time-intensive nature of function\n",
    "        df_acc.to_pickle(accname)\n",
    "        df_time.to_pickle(timename)\n",
    "    \n",
    "    return df_acc,df_time #return dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this step can be very time-consuming, the results are stored in a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-5 with CleanCountVec data has acc score of 0.6379797822393913 and took 1.6 minutes to cross-validate\n",
      "KNN-5 with DirtyCountVec data has acc score of 0.6356918276317612 and took 1.4 minutes to cross-validate\n",
      "KNN-5 with CleanTfIdf data has acc score of 0.7323630074689363 and took 1.4 minutes to cross-validate\n",
      "KNN-5 with DirtyTfIdf data has acc score of 0.72999967285177 and took 1.4 minutes to cross-validate\n",
      "KNN-5 with CleanW2V data has acc score of 0.6970635870270396 and took 16.8 minutes to cross-validate\n",
      "KNN-5 with DirtyW2V data has acc score of 0.6020014043667493 and took 4.8 minutes to cross-validate\n",
      "KNN-5 with CleanSpaCy data has acc score of 0.701664495424429 and took 21.2 minutes to cross-validate\n",
      "KNN-5 with DirtySpaCy data has acc score of 0.6979184585407576 and took 20.9 minutes to cross-validate\n",
      "KNN-10 with CleanCountVec data has acc score of 0.6470056596643776 and took 1.5 minutes to cross-validate\n",
      "KNN-10 with DirtyCountVec data has acc score of 0.6445165452451534 and took 1.4 minutes to cross-validate\n",
      "KNN-10 with CleanTfIdf data has acc score of 0.7429478204894991 and took 1.4 minutes to cross-validate\n",
      "KNN-10 with DirtyTfIdf data has acc score of 0.7410621760225002 and took 1.4 minutes to cross-validate\n",
      "KNN-10 with CleanW2V data has acc score of 0.7031478487159115 and took 16.2 minutes to cross-validate\n",
      "KNN-10 with DirtyW2V data has acc score of 0.6178660516069221 and took 6.0 minutes to cross-validate\n",
      "KNN-10 with CleanSpaCy data has acc score of 0.7069694489385621 and took 20.1 minutes to cross-validate\n",
      "KNN-10 with DirtySpaCy data has acc score of 0.7016142031008911 and took 19.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-1 with CleanCountVec data has acc score of 0.7735204895148993 and took 2.5 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-1 with DirtyCountVec data has acc score of 0.7748278433803926 and took 2.5 minutes to cross-validate\n",
      "SVC-1 with CleanTfIdf data has acc score of 0.7885806239427937 and took 0.2 minutes to cross-validate\n",
      "SVC-1 with DirtyTfIdf data has acc score of 0.789837698128159 and took 0.2 minutes to cross-validate\n",
      "SVC-1 with CleanW2V data has acc score of 0.7056368999180865 and took 19.0 minutes to cross-validate\n",
      "SVC-1 with DirtyW2V data has acc score of 0.6277468542801181 and took 19.6 minutes to cross-validate\n",
      "SVC-1 with CleanSpaCy data has acc score of 0.7624829886871509 and took 12.7 minutes to cross-validate\n",
      "SVC-1 with DirtySpaCy data has acc score of 0.7610247641727488 and took 12.6 minutes to cross-validate\n",
      "SVC-0.5 with CleanCountVec data has acc score of 0.778775182314019 and took 1.4 minutes to cross-validate\n",
      "SVC-0.5 with DirtyCountVec data has acc score of 0.7792025706580912 and took 1.4 minutes to cross-validate\n",
      "SVC-0.5 with CleanTfIdf data has acc score of 0.7900639740734238 and took 0.2 minutes to cross-validate\n",
      "SVC-0.5 with DirtyTfIdf data has acc score of 0.7910947881177867 and took 0.1 minutes to cross-validate\n",
      "SVC-0.5 with CleanW2V data has acc score of 0.7021170251889913 and took 9.8 minutes to cross-validate\n",
      "SVC-0.5 with DirtyW2V data has acc score of 0.6186956521051988 and took 10.3 minutes to cross-validate\n",
      "SVC-0.5 with CleanSpaCy data has acc score of 0.7611001821125146 and took 7.1 minutes to cross-validate\n",
      "SVC-0.5 with DirtySpaCy data has acc score of 0.7595665112106745 and took 7.0 minutes to cross-validate\n",
      "LogReg-1 with CleanCountVec data has acc score of 0.7826470716993549 and took 2.0 minutes to cross-validate\n",
      "LogReg-1 with DirtyCountVec data has acc score of 0.7834013775311119 and took 2.2 minutes to cross-validate\n",
      "LogReg-1 with CleanTfIdf data has acc score of 0.7824207293761883 and took 1.2 minutes to cross-validate\n",
      "LogReg-1 with DirtyTfIdf data has acc score of 0.7825464554437545 and took 1.2 minutes to cross-validate\n",
      "LogReg-1 with CleanW2V data has acc score of 0.7108916243257308 and took 3.2 minutes to cross-validate\n",
      "LogReg-1 with DirtyW2V data has acc score of 0.6303867287184151 and took 3.8 minutes to cross-validate\n",
      "LogReg-1 with CleanSpaCy data has acc score of 0.7587368759430206 and took 7.8 minutes to cross-validate\n",
      "LogReg-1 with DirtySpaCy data has acc score of 0.7580580955200131 and took 6.9 minutes to cross-validate\n",
      "LogReg-0.5 with CleanCountVec data has acc score of 0.7831499064308649 and took 1.7 minutes to cross-validate\n",
      "LogReg-0.5 with DirtyCountVec data has acc score of 0.7835521818021189 and took 1.5 minutes to cross-validate\n",
      "LogReg-0.5 with CleanTfIdf data has acc score of 0.7685171224168131 and took 0.9 minutes to cross-validate\n",
      "LogReg-0.5 with DirtyTfIdf data has acc score of 0.7692462394152929 and took 0.9 minutes to cross-validate\n",
      "LogReg-0.5 with CleanW2V data has acc score of 0.7086036665572485 and took 2.6 minutes to cross-validate\n",
      "LogReg-0.5 with DirtyW2V data has acc score of 0.6225423969091921 and took 2.8 minutes to cross-validate\n",
      "LogReg-0.5 with CleanSpaCy data has acc score of 0.7520993639258546 and took 6.5 minutes to cross-validate\n",
      "LogReg-0.5 with DirtySpaCy data has acc score of 0.7507416766457412 and took 5.4 minutes to cross-validate\n",
      "ExTrees with CleanCountVec data has acc score of 0.7778951124844664 and took 14.8 minutes to cross-validate\n",
      "ExTrees with DirtyCountVec data has acc score of 0.777819704027258 and took 14.5 minutes to cross-validate\n",
      "ExTrees with CleanTfIdf data has acc score of 0.77382217075652 and took 13.9 minutes to cross-validate\n",
      "ExTrees with DirtyTfIdf data has acc score of 0.7732187608604916 and took 13.8 minutes to cross-validate\n",
      "ExTrees with CleanW2V data has acc score of 0.6966359552973278 and took 3.4 minutes to cross-validate\n",
      "ExTrees with DirtyW2V data has acc score of 0.6530899276749544 and took 3.5 minutes to cross-validate\n",
      "ExTrees with CleanSpaCy data has acc score of 0.6763715183802781 and took 3.5 minutes to cross-validate\n",
      "ExTrees with DirtySpaCy data has acc score of 0.6711419511973863 and took 3.5 minutes to cross-validate\n",
      "RandomForest with CleanCountVec data has acc score of 0.7606981280009331 and took 10.4 minutes to cross-validate\n",
      "RandomForest with DirtyCountVec data has acc score of 0.7594660308717299 and took 11.3 minutes to cross-validate\n",
      "RandomForest with CleanTfIdf data has acc score of 0.7504903699098224 and took 10.6 minutes to cross-validate\n",
      "RandomForest with DirtyTfIdf data has acc score of 0.751621787566376 and took 10.4 minutes to cross-validate\n",
      "RandomForest with CleanW2V data has acc score of 0.6984211605164643 and took 18.1 minutes to cross-validate\n",
      "RandomForest with DirtyW2V data has acc score of 0.6519083346464042 and took 18.7 minutes to cross-validate\n",
      "RandomForest with CleanSpaCy data has acc score of 0.6820285434459962 and took 15.6 minutes to cross-validate\n",
      "RandomForest with DirtySpaCy data has acc score of 0.678785157964392 and took 16.4 minutes to cross-validate\n",
      "BernoulliNB with CleanCountVec data has acc score of 0.716925675873229 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with DirtyCountVec data has acc score of 0.7158194027980181 and took 0.1 minutes to cross-validate\n",
      "BernoulliNB with CleanTfIdf data has acc score of 0.716925675873229 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with DirtyTfIdf data has acc score of 0.7158194027980181 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with CleanW2V data has acc score of 0.509378103858342 and took 0.1 minutes to cross-validate\n",
      "BernoulliNB with DirtyW2V data has acc score of 0.48375830731293246 and took 0.1 minutes to cross-validate\n",
      "BernoulliNB with CleanSpaCy data has acc score of 0.47432998383065916 and took 0.1 minutes to cross-validate\n",
      "BernoulliNB with DirtySpaCy data has acc score of 0.47314829281568266 and took 0.1 minutes to cross-validate\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('accuracy1.pickle') and os.path.isfile('time1.pickle'):\n",
    "    accuracy_df = pd.read_pickle('accuracy1.pickle')\n",
    "    time_df = pd.read_pickle('time1.pickle')\n",
    "    \n",
    "else:\n",
    "    accuracy_df, time_df = approach_analyzer(models,data,y,True,True,accname='accuracy1.pickle',timename='time1.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN-5</th>\n",
       "      <th>KNN-10</th>\n",
       "      <th>SVC-1</th>\n",
       "      <th>SVC-0.5</th>\n",
       "      <th>LogReg-1</th>\n",
       "      <th>LogReg-0.5</th>\n",
       "      <th>ExTrees</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>BernoulliNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CleanCountVec</th>\n",
       "      <td>0.637980</td>\n",
       "      <td>0.647006</td>\n",
       "      <td>0.773520</td>\n",
       "      <td>0.778775</td>\n",
       "      <td>0.782647</td>\n",
       "      <td>0.783150</td>\n",
       "      <td>0.777895</td>\n",
       "      <td>0.760698</td>\n",
       "      <td>0.716926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyCountVec</th>\n",
       "      <td>0.635692</td>\n",
       "      <td>0.644517</td>\n",
       "      <td>0.774828</td>\n",
       "      <td>0.779203</td>\n",
       "      <td>0.783401</td>\n",
       "      <td>0.783552</td>\n",
       "      <td>0.777820</td>\n",
       "      <td>0.759466</td>\n",
       "      <td>0.715819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanTfIdf</th>\n",
       "      <td>0.732363</td>\n",
       "      <td>0.742948</td>\n",
       "      <td>0.788581</td>\n",
       "      <td>0.790064</td>\n",
       "      <td>0.782421</td>\n",
       "      <td>0.768517</td>\n",
       "      <td>0.773822</td>\n",
       "      <td>0.750490</td>\n",
       "      <td>0.716926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyTfIdf</th>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.741062</td>\n",
       "      <td>0.789838</td>\n",
       "      <td>0.791095</td>\n",
       "      <td>0.782546</td>\n",
       "      <td>0.769246</td>\n",
       "      <td>0.773219</td>\n",
       "      <td>0.751622</td>\n",
       "      <td>0.715819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanW2V</th>\n",
       "      <td>0.697064</td>\n",
       "      <td>0.703148</td>\n",
       "      <td>0.705637</td>\n",
       "      <td>0.702117</td>\n",
       "      <td>0.710892</td>\n",
       "      <td>0.708604</td>\n",
       "      <td>0.696636</td>\n",
       "      <td>0.698421</td>\n",
       "      <td>0.509378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyW2V</th>\n",
       "      <td>0.602001</td>\n",
       "      <td>0.617866</td>\n",
       "      <td>0.627747</td>\n",
       "      <td>0.618696</td>\n",
       "      <td>0.630387</td>\n",
       "      <td>0.622542</td>\n",
       "      <td>0.653090</td>\n",
       "      <td>0.651908</td>\n",
       "      <td>0.483758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanSpaCy</th>\n",
       "      <td>0.701664</td>\n",
       "      <td>0.706969</td>\n",
       "      <td>0.762483</td>\n",
       "      <td>0.761100</td>\n",
       "      <td>0.758737</td>\n",
       "      <td>0.752099</td>\n",
       "      <td>0.676372</td>\n",
       "      <td>0.682029</td>\n",
       "      <td>0.474330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtySpaCy</th>\n",
       "      <td>0.697918</td>\n",
       "      <td>0.701614</td>\n",
       "      <td>0.761025</td>\n",
       "      <td>0.759567</td>\n",
       "      <td>0.758058</td>\n",
       "      <td>0.750742</td>\n",
       "      <td>0.671142</td>\n",
       "      <td>0.678785</td>\n",
       "      <td>0.473148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  KNN-5    KNN-10     SVC-1   SVC-0.5  LogReg-1  LogReg-0.5  \\\n",
       "CleanCountVec  0.637980  0.647006  0.773520  0.778775  0.782647    0.783150   \n",
       "DirtyCountVec  0.635692  0.644517  0.774828  0.779203  0.783401    0.783552   \n",
       "CleanTfIdf     0.732363  0.742948  0.788581  0.790064  0.782421    0.768517   \n",
       "DirtyTfIdf     0.730000  0.741062  0.789838  0.791095  0.782546    0.769246   \n",
       "CleanW2V       0.697064  0.703148  0.705637  0.702117  0.710892    0.708604   \n",
       "DirtyW2V       0.602001  0.617866  0.627747  0.618696  0.630387    0.622542   \n",
       "CleanSpaCy     0.701664  0.706969  0.762483  0.761100  0.758737    0.752099   \n",
       "DirtySpaCy     0.697918  0.701614  0.761025  0.759567  0.758058    0.750742   \n",
       "\n",
       "                ExTrees  RandomForest  BernoulliNB  \n",
       "CleanCountVec  0.777895      0.760698     0.716926  \n",
       "DirtyCountVec  0.777820      0.759466     0.715819  \n",
       "CleanTfIdf     0.773822      0.750490     0.716926  \n",
       "DirtyTfIdf     0.773219      0.751622     0.715819  \n",
       "CleanW2V       0.696636      0.698421     0.509378  \n",
       "DirtyW2V       0.653090      0.651908     0.483758  \n",
       "CleanSpaCy     0.676372      0.682029     0.474330  \n",
       "DirtySpaCy     0.671142      0.678785     0.473148  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df #check the accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN-5</th>\n",
       "      <th>KNN-10</th>\n",
       "      <th>SVC-1</th>\n",
       "      <th>SVC-0.5</th>\n",
       "      <th>LogReg-1</th>\n",
       "      <th>LogReg-0.5</th>\n",
       "      <th>ExTrees</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>BernoulliNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CleanCountVec</th>\n",
       "      <td>95.1</td>\n",
       "      <td>89.1</td>\n",
       "      <td>151.1</td>\n",
       "      <td>83.2</td>\n",
       "      <td>122.6</td>\n",
       "      <td>100.4</td>\n",
       "      <td>886.6</td>\n",
       "      <td>621.5</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyCountVec</th>\n",
       "      <td>83.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>149.4</td>\n",
       "      <td>85.2</td>\n",
       "      <td>130.7</td>\n",
       "      <td>89.0</td>\n",
       "      <td>870.8</td>\n",
       "      <td>680.9</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanTfIdf</th>\n",
       "      <td>82.5</td>\n",
       "      <td>83.3</td>\n",
       "      <td>11.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>72.1</td>\n",
       "      <td>51.6</td>\n",
       "      <td>833.8</td>\n",
       "      <td>635.5</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyTfIdf</th>\n",
       "      <td>84.2</td>\n",
       "      <td>84.1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>69.9</td>\n",
       "      <td>51.4</td>\n",
       "      <td>829.0</td>\n",
       "      <td>626.2</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanW2V</th>\n",
       "      <td>1006.0</td>\n",
       "      <td>971.4</td>\n",
       "      <td>1139.9</td>\n",
       "      <td>586.9</td>\n",
       "      <td>194.3</td>\n",
       "      <td>156.4</td>\n",
       "      <td>203.9</td>\n",
       "      <td>1088.5</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyW2V</th>\n",
       "      <td>290.5</td>\n",
       "      <td>358.9</td>\n",
       "      <td>1176.5</td>\n",
       "      <td>615.6</td>\n",
       "      <td>226.3</td>\n",
       "      <td>165.1</td>\n",
       "      <td>207.2</td>\n",
       "      <td>1121.2</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanSpaCy</th>\n",
       "      <td>1272.7</td>\n",
       "      <td>1204.3</td>\n",
       "      <td>763.7</td>\n",
       "      <td>423.5</td>\n",
       "      <td>469.1</td>\n",
       "      <td>388.5</td>\n",
       "      <td>211.1</td>\n",
       "      <td>935.2</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtySpaCy</th>\n",
       "      <td>1256.7</td>\n",
       "      <td>1140.8</td>\n",
       "      <td>758.3</td>\n",
       "      <td>420.2</td>\n",
       "      <td>411.9</td>\n",
       "      <td>321.1</td>\n",
       "      <td>210.3</td>\n",
       "      <td>986.3</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                KNN-5  KNN-10   SVC-1  SVC-0.5  LogReg-1  LogReg-0.5  ExTrees  \\\n",
       "CleanCountVec    95.1    89.1   151.1     83.2     122.6       100.4    886.6   \n",
       "DirtyCountVec    83.0    82.5   149.4     85.2     130.7        89.0    870.8   \n",
       "CleanTfIdf       82.5    83.3    11.6      9.3      72.1        51.6    833.8   \n",
       "DirtyTfIdf       84.2    84.1    11.5      9.0      69.9        51.4    829.0   \n",
       "CleanW2V       1006.0   971.4  1139.9    586.9     194.3       156.4    203.9   \n",
       "DirtyW2V        290.5   358.9  1176.5    615.6     226.3       165.1    207.2   \n",
       "CleanSpaCy     1272.7  1204.3   763.7    423.5     469.1       388.5    211.1   \n",
       "DirtySpaCy     1256.7  1140.8   758.3    420.2     411.9       321.1    210.3   \n",
       "\n",
       "               RandomForest  BernoulliNB  \n",
       "CleanCountVec         621.5          2.4  \n",
       "DirtyCountVec         680.9          3.2  \n",
       "CleanTfIdf            635.5          2.4  \n",
       "DirtyTfIdf            626.2          2.1  \n",
       "CleanW2V             1088.5          5.3  \n",
       "DirtyW2V             1121.2          4.4  \n",
       "CleanSpaCy            935.2          4.1  \n",
       "DirtySpaCy            986.3          3.7  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df #check the time scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt with Smaller Datasets\n",
    "Again, since a faster model improves the user experience, the cross validation step will be attempted with a smaller dataset, to see what kind of accuracy tradeoff is made for the faster time. First, we'll define a function to get the data vectors for the specified fraction of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec_dict(df, nlp, s_frac):\n",
    "    \n",
    "    '''\n",
    "    accepts the recipe dataframe, the SpaCy model and deisred sample fraction as arguments\n",
    "    gets dataframe of desired sample size, and vectorized the recipe ingredients as shown above\n",
    "    returns dictionary of data vectors, along with cuisine labels\n",
    "    '''\n",
    "    \n",
    "    samp_df = df.sample(frac=s_frac)\n",
    "    \n",
    "    y = samp_df['cuisine']\n",
    "    \n",
    "    clean_cmat = CountVectorizer(min_df=2).fit_transform(samp_df['ing_clean'])\n",
    " \n",
    "    dirt_cmat = CountVectorizer(min_df=2).fit_transform(samp_df['ing_join'])\n",
    " \n",
    "    clean_mat = TfidfVectorizer(min_df=2).fit_transform(samp_df['ing_clean'])\n",
    "\n",
    "    dirt_mat = TfidfVectorizer(min_df=2).fit_transform(samp_df['ing_join'])\n",
    "    \n",
    "    clean_mod = get_model(samp_df, clean=True) \n",
    "    clean_w2vs = get_recipe_vectors(samp_df,clean_mod, zeros=True, clean=True)\n",
    "    \n",
    "    dirt_mod = get_model(samp_df, clean=False)\n",
    "    dirt_w2vs = get_recipe_vectors(samp_df,dirt_mod, zeros=True, clean=False)\n",
    "    \n",
    "    dirt_spacy = np.array([nlp(recipe).vector for recipe in samp_df['ing_join']])\n",
    "    \n",
    "    clean_spacy = np.array([nlp(recipe).vector for recipe in samp_df['ing_clean']])\n",
    "    \n",
    "    ret_dict = {'CleanCountVec': clean_cmat, 'DirtyCountVec': dirt_cmat, 'CleanTfIdf': clean_mat, 'DirtyTfIdf': dirt_mat, \n",
    "                'CleanW2V':clean_w2vs, 'DirtyW2V': dirt_w2vs, 'CleanSpaCy': clean_spacy, 'DirtySpaCy': dirt_spacy}\n",
    "    \n",
    "    return ret_dict,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Experiment with 10% of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%time data01,y01 = get_vec_dict(df, nlp, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-5 with CleanCountVec data has acc score of 0.5119446288043994 and took 0.0 minutes to cross-validate\n",
      "KNN-5 with DirtyCountVec data has acc score of 0.5101848866976393 and took 0.0 minutes to cross-validate\n",
      "KNN-5 with CleanTfIdf data has acc score of 0.6590458582219273 and took 0.0 minutes to cross-validate\n",
      "KNN-5 with DirtyTfIdf data has acc score of 0.6580411491419361 and took 0.0 minutes to cross-validate\n",
      "KNN-5 with CleanW2V data has acc score of 0.40683259062608645 and took 0.1 minutes to cross-validate\n",
      "KNN-5 with DirtyW2V data has acc score of 0.2763326064283682 and took 0.0 minutes to cross-validate\n",
      "KNN-5 with CleanSpaCy data has acc score of 0.5986928352454094 and took 0.2 minutes to cross-validate\n",
      "KNN-5 with DirtySpaCy data has acc score of 0.5939161214879428 and took 0.2 minutes to cross-validate\n",
      "KNN-10 with CleanCountVec data has acc score of 0.5240156758635947 and took 0.0 minutes to cross-validate\n",
      "KNN-10 with DirtyCountVec data has acc score of 0.5320615656900857 and took 0.0 minutes to cross-validate\n",
      "KNN-10 with CleanTfIdf data has acc score of 0.6716184697070257 and took 0.0 minutes to cross-validate\n",
      "KNN-10 with DirtyTfIdf data has acc score of 0.673881672513511 and took 0.0 minutes to cross-validate\n",
      "KNN-10 with CleanW2V data has acc score of 0.4334929363800133 and took 0.1 minutes to cross-validate\n",
      "KNN-10 with DirtyW2V data has acc score of 0.284634809266458 and took 0.0 minutes to cross-validate\n",
      "KNN-10 with CleanSpaCy data has acc score of 0.612524888593913 and took 0.2 minutes to cross-validate\n",
      "KNN-10 with DirtySpaCy data has acc score of 0.602967984576973 and took 0.2 minutes to cross-validate\n",
      "SVC-1 with CleanCountVec data has acc score of 0.6728788597073417 and took 0.0 minutes to cross-validate\n",
      "SVC-1 with DirtyCountVec data has acc score of 0.6741370373881989 and took 0.0 minutes to cross-validate\n",
      "SVC-1 with CleanTfIdf data has acc score of 0.7244240068265857 and took 0.0 minutes to cross-validate\n",
      "SVC-1 with DirtyTfIdf data has acc score of 0.7239214942637717 and took 0.0 minutes to cross-validate\n",
      "SVC-1 with CleanW2V data has acc score of 0.4704528933978066 and took 1.5 minutes to cross-validate\n",
      "SVC-1 with DirtyW2V data has acc score of 0.2632638032931955 and took 1.9 minutes to cross-validate\n",
      "SVC-1 with CleanSpaCy data has acc score of 0.7118463386112955 and took 0.8 minutes to cross-validate\n",
      "SVC-1 with DirtySpaCy data has acc score of 0.7090818874245441 and took 0.8 minutes to cross-validate\n",
      "SVC-0.5 with CleanCountVec data has acc score of 0.6894728358775006 and took 0.0 minutes to cross-validate\n",
      "SVC-0.5 with DirtyCountVec data has acc score of 0.6892225277330046 and took 0.0 minutes to cross-validate\n",
      "SVC-0.5 with CleanTfIdf data has acc score of 0.7274412945229292 and took 0.0 minutes to cross-validate\n",
      "SVC-0.5 with DirtyTfIdf data has acc score of 0.7254296640434879 and took 0.0 minutes to cross-validate\n",
      "SVC-0.5 with CleanW2V data has acc score of 0.4598934926203344 and took 0.7 minutes to cross-validate\n",
      "SVC-0.5 with DirtyW2V data has acc score of 0.23284125027653993 and took 0.8 minutes to cross-validate\n",
      "SVC-0.5 with CleanSpaCy data has acc score of 0.7115947662842514 and took 0.5 minutes to cross-validate\n",
      "SVC-0.5 with DirtySpaCy data has acc score of 0.7103375367403053 and took 0.5 minutes to cross-validate\n",
      "LogReg-1 with CleanCountVec data has acc score of 0.7038064536519073 and took 0.1 minutes to cross-validate\n",
      "LogReg-1 with DirtyCountVec data has acc score of 0.7040583420245883 and took 0.1 minutes to cross-validate\n",
      "LogReg-1 with CleanTfIdf data has acc score of 0.6821813469865048 and took 0.1 minutes to cross-validate\n",
      "LogReg-1 with DirtyTfIdf data has acc score of 0.6824335514048229 and took 0.1 minutes to cross-validate\n",
      "LogReg-1 with CleanW2V data has acc score of 0.45587339211782185 and took 0.2 minutes to cross-validate\n",
      "LogReg-1 with DirtyW2V data has acc score of 0.21297493758098668 and took 0.1 minutes to cross-validate\n",
      "LogReg-1 with CleanSpaCy data has acc score of 0.6849426377168862 and took 0.3 minutes to cross-validate\n",
      "LogReg-1 with DirtySpaCy data has acc score of 0.6846923295723902 and took 0.3 minutes to cross-validate\n",
      "LogReg-0.5 with CleanCountVec data has acc score of 0.7022973357352802 and took 0.1 minutes to cross-validate\n",
      "LogReg-0.5 with DirtyCountVec data has acc score of 0.7043102303972694 and took 0.1 minutes to cross-validate\n",
      "LogReg-0.5 with CleanTfIdf data has acc score of 0.6364166745678076 and took 0.1 minutes to cross-validate\n",
      "LogReg-0.5 with DirtyTfIdf data has acc score of 0.6346559843241363 and took 0.0 minutes to cross-validate\n",
      "LogReg-0.5 with CleanW2V data has acc score of 0.44128820201637114 and took 0.1 minutes to cross-validate\n",
      "LogReg-0.5 with DirtyW2V data has acc score of 0.21071110268322743 and took 0.1 minutes to cross-validate\n",
      "LogReg-0.5 with CleanSpaCy data has acc score of 0.6756395183464492 and took 0.3 minutes to cross-validate\n",
      "LogReg-0.5 with DirtySpaCy data has acc score of 0.6708618564520716 and took 0.3 minutes to cross-validate\n",
      "ExTrees with CleanCountVec data has acc score of 0.6894699914667678 and took 0.5 minutes to cross-validate\n",
      "ExTrees with DirtyCountVec data has acc score of 0.6899718719383079 and took 0.5 minutes to cross-validate\n",
      "ExTrees with CleanTfIdf data has acc score of 0.689215258683354 and took 0.5 minutes to cross-validate\n",
      "ExTrees with DirtyTfIdf data has acc score of 0.6854435700515153 and took 0.5 minutes to cross-validate\n",
      "ExTrees with CleanW2V data has acc score of 0.4732224013147498 and took 0.3 minutes to cross-validate\n",
      "ExTrees with DirtyW2V data has acc score of 0.4131200025283651 and took 0.4 minutes to cross-validate\n",
      "ExTrees with CleanSpaCy data has acc score of 0.6034704971397871 and took 0.3 minutes to cross-validate\n",
      "ExTrees with DirtySpaCy data has acc score of 0.6027148320217439 and took 0.3 minutes to cross-validate\n",
      "RandomForest with CleanCountVec data has acc score of 0.6678429885275434 and took 0.4 minutes to cross-validate\n",
      "RandomForest with DirtyCountVec data has acc score of 0.6663357668847382 and took 0.4 minutes to cross-validate\n",
      "RandomForest with CleanTfIdf data has acc score of 0.6565263424038431 and took 0.4 minutes to cross-validate\n",
      "RandomForest with DirtyTfIdf data has acc score of 0.6580367245030182 and took 0.4 minutes to cross-validate\n",
      "RandomForest with CleanW2V data has acc score of 0.4915814923674978 and took 1.1 minutes to cross-validate\n",
      "RandomForest with DirtyW2V data has acc score of 0.42946841123858287 and took 1.1 minutes to cross-validate\n",
      "RandomForest with CleanSpaCy data has acc score of 0.6145352548908062 and took 1.0 minutes to cross-validate\n",
      "RandomForest with DirtySpaCy data has acc score of 0.6095053885781108 and took 1.0 minutes to cross-validate\n",
      "BernoulliNB with CleanCountVec data has acc score of 0.6321374166429632 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with DirtyCountVec data has acc score of 0.6328911854871844 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with CleanTfIdf data has acc score of 0.6321374166429632 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with DirtyTfIdf data has acc score of 0.6328911854871844 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with CleanW2V data has acc score of 0.30072848519326184 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with DirtyW2V data has acc score of 0.28363547296229574 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with CleanSpaCy data has acc score of 0.47497613855440723 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with DirtySpaCy data has acc score of 0.4644186340507569 and took 0.0 minutes to cross-validate\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('accuracy01.pickle') and os.path.isfile('time01.pickle'):\n",
    "    accuracy_df01 = pd.read_pickle('accuracy01.pickle')\n",
    "    time_df01 = pd.read_pickle('time01.pickle')\n",
    "    \n",
    "else:\n",
    "    accuracy_df01, time_df01 = approach_analyzer(models,data01,y01,True,True,\n",
    "                                                 accname='accuracy01.pickle',timename='time01.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN-5</th>\n",
       "      <th>KNN-10</th>\n",
       "      <th>SVC-1</th>\n",
       "      <th>SVC-0.5</th>\n",
       "      <th>LogReg-1</th>\n",
       "      <th>LogReg-0.5</th>\n",
       "      <th>ExTrees</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>BernoulliNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CleanCountVec</th>\n",
       "      <td>0.511945</td>\n",
       "      <td>0.524016</td>\n",
       "      <td>0.672879</td>\n",
       "      <td>0.689473</td>\n",
       "      <td>0.703806</td>\n",
       "      <td>0.702297</td>\n",
       "      <td>0.689470</td>\n",
       "      <td>0.667843</td>\n",
       "      <td>0.632137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyCountVec</th>\n",
       "      <td>0.510185</td>\n",
       "      <td>0.532062</td>\n",
       "      <td>0.674137</td>\n",
       "      <td>0.689223</td>\n",
       "      <td>0.704058</td>\n",
       "      <td>0.704310</td>\n",
       "      <td>0.689972</td>\n",
       "      <td>0.666336</td>\n",
       "      <td>0.632891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanTfIdf</th>\n",
       "      <td>0.659046</td>\n",
       "      <td>0.671618</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.727441</td>\n",
       "      <td>0.682181</td>\n",
       "      <td>0.636417</td>\n",
       "      <td>0.689215</td>\n",
       "      <td>0.656526</td>\n",
       "      <td>0.632137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyTfIdf</th>\n",
       "      <td>0.658041</td>\n",
       "      <td>0.673882</td>\n",
       "      <td>0.723921</td>\n",
       "      <td>0.725430</td>\n",
       "      <td>0.682434</td>\n",
       "      <td>0.634656</td>\n",
       "      <td>0.685444</td>\n",
       "      <td>0.658037</td>\n",
       "      <td>0.632891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanW2V</th>\n",
       "      <td>0.406833</td>\n",
       "      <td>0.433493</td>\n",
       "      <td>0.470453</td>\n",
       "      <td>0.459893</td>\n",
       "      <td>0.455873</td>\n",
       "      <td>0.441288</td>\n",
       "      <td>0.473222</td>\n",
       "      <td>0.491581</td>\n",
       "      <td>0.300728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyW2V</th>\n",
       "      <td>0.276333</td>\n",
       "      <td>0.284635</td>\n",
       "      <td>0.263264</td>\n",
       "      <td>0.232841</td>\n",
       "      <td>0.212975</td>\n",
       "      <td>0.210711</td>\n",
       "      <td>0.413120</td>\n",
       "      <td>0.429468</td>\n",
       "      <td>0.283635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanSpaCy</th>\n",
       "      <td>0.598693</td>\n",
       "      <td>0.612525</td>\n",
       "      <td>0.711846</td>\n",
       "      <td>0.711595</td>\n",
       "      <td>0.684943</td>\n",
       "      <td>0.675640</td>\n",
       "      <td>0.603470</td>\n",
       "      <td>0.614535</td>\n",
       "      <td>0.474976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtySpaCy</th>\n",
       "      <td>0.593916</td>\n",
       "      <td>0.602968</td>\n",
       "      <td>0.709082</td>\n",
       "      <td>0.710338</td>\n",
       "      <td>0.684692</td>\n",
       "      <td>0.670862</td>\n",
       "      <td>0.602715</td>\n",
       "      <td>0.609505</td>\n",
       "      <td>0.464419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  KNN-5    KNN-10     SVC-1   SVC-0.5  LogReg-1  LogReg-0.5  \\\n",
       "CleanCountVec  0.511945  0.524016  0.672879  0.689473  0.703806    0.702297   \n",
       "DirtyCountVec  0.510185  0.532062  0.674137  0.689223  0.704058    0.704310   \n",
       "CleanTfIdf     0.659046  0.671618  0.724424  0.727441  0.682181    0.636417   \n",
       "DirtyTfIdf     0.658041  0.673882  0.723921  0.725430  0.682434    0.634656   \n",
       "CleanW2V       0.406833  0.433493  0.470453  0.459893  0.455873    0.441288   \n",
       "DirtyW2V       0.276333  0.284635  0.263264  0.232841  0.212975    0.210711   \n",
       "CleanSpaCy     0.598693  0.612525  0.711846  0.711595  0.684943    0.675640   \n",
       "DirtySpaCy     0.593916  0.602968  0.709082  0.710338  0.684692    0.670862   \n",
       "\n",
       "                ExTrees  RandomForest  BernoulliNB  \n",
       "CleanCountVec  0.689470      0.667843     0.632137  \n",
       "DirtyCountVec  0.689972      0.666336     0.632891  \n",
       "CleanTfIdf     0.689215      0.656526     0.632137  \n",
       "DirtyTfIdf     0.685444      0.658037     0.632891  \n",
       "CleanW2V       0.473222      0.491581     0.300728  \n",
       "DirtyW2V       0.413120      0.429468     0.283635  \n",
       "CleanSpaCy     0.603470      0.614535     0.474976  \n",
       "DirtySpaCy     0.602715      0.609505     0.464419  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN-5</th>\n",
       "      <th>KNN-10</th>\n",
       "      <th>SVC-1</th>\n",
       "      <th>SVC-0.5</th>\n",
       "      <th>LogReg-1</th>\n",
       "      <th>LogReg-0.5</th>\n",
       "      <th>ExTrees</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>BernoulliNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CleanCountVec</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>29.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyCountVec</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>32.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanTfIdf</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>32.5</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyTfIdf</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanW2V</th>\n",
       "      <td>3.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>87.7</td>\n",
       "      <td>40.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.2</td>\n",
       "      <td>20.6</td>\n",
       "      <td>64.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyW2V</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>111.3</td>\n",
       "      <td>48.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>66.8</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanSpaCy</th>\n",
       "      <td>11.7</td>\n",
       "      <td>11.5</td>\n",
       "      <td>50.3</td>\n",
       "      <td>29.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.1</td>\n",
       "      <td>57.1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtySpaCy</th>\n",
       "      <td>11.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>49.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>18.1</td>\n",
       "      <td>19.4</td>\n",
       "      <td>58.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               KNN-5  KNN-10  SVC-1  SVC-0.5  LogReg-1  LogReg-0.5  ExTrees  \\\n",
       "CleanCountVec    1.1     1.2    3.0      1.8       5.9         4.8     29.9   \n",
       "DirtyCountVec    1.0     1.2    2.7      1.9       5.8         4.8     32.2   \n",
       "CleanTfIdf       1.0     1.1    0.6      0.5       3.9         3.1     32.5   \n",
       "DirtyTfIdf       1.0     1.2    0.6      0.5       3.9         3.0     30.9   \n",
       "CleanW2V         3.9     4.7   87.7     40.5       9.7         8.2     20.6   \n",
       "DirtyW2V         2.0     2.2  111.3     48.4       5.3         5.1     22.4   \n",
       "CleanSpaCy      11.7    11.5   50.3     29.4      19.9        20.5     20.1   \n",
       "DirtySpaCy      11.7    11.6   49.8     28.8      18.7        18.1     19.4   \n",
       "\n",
       "               RandomForest  BernoulliNB  \n",
       "CleanCountVec          23.5          0.1  \n",
       "DirtyCountVec          25.0          0.1  \n",
       "CleanTfIdf             23.7          0.1  \n",
       "DirtyTfIdf             25.4          0.1  \n",
       "CleanW2V               64.5          0.3  \n",
       "DirtyW2V               66.8          0.3  \n",
       "CleanSpaCy             57.1          0.3  \n",
       "DirtySpaCy             58.7          0.3  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Experiment with 1% of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%time data001,y001 = get_vec_dict(df, nlp, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-5 with CleanCountVec data has acc score of 0.37443037974683546 and took 0.0 minutes to cross-validate\n",
      "KNN-5 with DirtyCountVec data has acc score of 0.3543670886075949 and took 0.0 minutes to cross-validate\n",
      "KNN-5 with CleanTfIdf data has acc score of 0.5279746835443038 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-5 with DirtyTfIdf data has acc score of 0.5355379746835444 and took 0.0 minutes to cross-validate\n",
      "KNN-5 with CleanW2V data has acc score of 0.11813291139240507 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-5 with DirtyW2V data has acc score of 0.29905063291139244 and took 0.0 minutes to cross-validate\n",
      "KNN-5 with CleanSpaCy data has acc score of 0.4800316455696202 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-5 with DirtySpaCy data has acc score of 0.4925316455696202 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-10 with CleanCountVec data has acc score of 0.3894936708860759 and took 0.0 minutes to cross-validate\n",
      "KNN-10 with DirtyCountVec data has acc score of 0.39958860759493675 and took 0.0 minutes to cross-validate\n",
      "KNN-10 with CleanTfIdf data has acc score of 0.5579746835443038 and took 0.0 minutes to cross-validate\n",
      "KNN-10 with DirtyTfIdf data has acc score of 0.5504430379746834 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-10 with CleanW2V data has acc score of 0.10813291139240506 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-10 with DirtyW2V data has acc score of 0.309240506329114 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-10 with CleanSpaCy data has acc score of 0.507626582278481 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-10 with DirtySpaCy data has acc score of 0.5378481012658227 and took 0.0 minutes to cross-validate\n",
      "SVC-1 with CleanCountVec data has acc score of 0.5203797468354431 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-1 with DirtyCountVec data has acc score of 0.5253797468354431 and took 0.0 minutes to cross-validate\n",
      "SVC-1 with CleanTfIdf data has acc score of 0.5780379746835445 and took 0.0 minutes to cross-validate\n",
      "SVC-1 with DirtyTfIdf data has acc score of 0.5756012658227848 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-1 with CleanW2V data has acc score of 0.20604430379746835 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-1 with DirtyW2V data has acc score of 0.19851265822784808 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-1 with CleanSpaCy data has acc score of 0.5829113924050633 and took 0.1 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-1 with DirtySpaCy data has acc score of 0.5779430379746835 and took 0.1 minutes to cross-validate\n",
      "SVC-0.5 with CleanCountVec data has acc score of 0.527879746835443 and took 0.0 minutes to cross-validate\n",
      "SVC-0.5 with DirtyCountVec data has acc score of 0.530379746835443 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-0.5 with CleanTfIdf data has acc score of 0.5779746835443038 and took 0.0 minutes to cross-validate\n",
      "SVC-0.5 with DirtyTfIdf data has acc score of 0.5805063291139241 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-0.5 with CleanW2V data has acc score of 0.20354430379746832 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-0.5 with DirtyW2V data has acc score of 0.19851265822784808 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-0.5 with CleanSpaCy data has acc score of 0.5904430379746836 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-0.5 with DirtySpaCy data has acc score of 0.5905696202531646 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-1 with CleanCountVec data has acc score of 0.5379113924050632 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-1 with DirtyCountVec data has acc score of 0.535379746835443 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-1 with CleanTfIdf data has acc score of 0.515126582278481 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-1 with DirtyTfIdf data has acc score of 0.5050949367088607 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-1 with CleanW2V data has acc score of 0.20104430379746838 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-1 with DirtyW2V data has acc score of 0.19851265822784808 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-1 with CleanSpaCy data has acc score of 0.547879746835443 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-1 with DirtySpaCy data has acc score of 0.5554430379746835 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-0.5 with CleanCountVec data has acc score of 0.5454430379746835 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-0.5 with DirtyCountVec data has acc score of 0.5329113924050632 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-0.5 with CleanTfIdf data has acc score of 0.46746835443037976 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-0.5 with DirtyTfIdf data has acc score of 0.4649683544303797 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-0.5 with CleanW2V data has acc score of 0.19854430379746835 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-0.5 with DirtyW2V data has acc score of 0.19851265822784808 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-0.5 with CleanSpaCy data has acc score of 0.5201898734177215 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg-0.5 with DirtySpaCy data has acc score of 0.5177215189873419 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExTrees with CleanCountVec data has acc score of 0.5905379746835442 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExTrees with DirtyCountVec data has acc score of 0.5905379746835442 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExTrees with CleanTfIdf data has acc score of 0.5704746835443039 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExTrees with DirtyTfIdf data has acc score of 0.5779746835443038 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExTrees with CleanW2V data has acc score of 0.18348101265822786 and took 0.1 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExTrees with DirtyW2V data has acc score of 0.34436708860759496 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExTrees with CleanSpaCy data has acc score of 0.5252848101265822 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExTrees with DirtySpaCy data has acc score of 0.5253481012658228 and took 0.1 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with CleanCountVec data has acc score of 0.5830696202531646 and took 0.1 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with DirtyCountVec data has acc score of 0.5579113924050633 and took 0.1 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with CleanTfIdf data has acc score of 0.5654430379746835 and took 0.1 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with DirtyTfIdf data has acc score of 0.547879746835443 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with CleanW2V data has acc score of 0.20860759493670886 and took 0.1 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with DirtyW2V data has acc score of 0.3543670886075949 and took 0.1 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with CleanSpaCy data has acc score of 0.5277848101265823 and took 0.1 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with DirtySpaCy data has acc score of 0.5202531645569619 and took 0.1 minutes to cross-validate\n",
      "BernoulliNB with CleanCountVec data has acc score of 0.5151582278481012 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with DirtyCountVec data has acc score of 0.5101582278481013 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with CleanTfIdf data has acc score of 0.5151582278481012 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with DirtyTfIdf data has acc score of 0.5101582278481013 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with CleanW2V data has acc score of 0.19851265822784808 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB with DirtyW2V data has acc score of 0.3141772151898734 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with CleanSpaCy data has acc score of 0.5126265822784811 and took 0.0 minutes to cross-validate\n",
      "BernoulliNB with DirtySpaCy data has acc score of 0.5025316455696203 and took 0.0 minutes to cross-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('accuracy001.pickle') and os.path.isfile('time001.pickle'):\n",
    "    accuracy_df001 = pd.read_pickle('accuracy001.pickle')\n",
    "    time_df001 = pd.read_pickle('time001.pickle')\n",
    "    \n",
    "else:\n",
    "    accuracy_df001, time_df001 = approach_analyzer(models,data001,y001,True,True,\n",
    "                                                   accname='accuracy001.pickle',timename='time001.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the small training set size caused some problems with fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN-5</th>\n",
       "      <th>KNN-10</th>\n",
       "      <th>SVC-1</th>\n",
       "      <th>SVC-0.5</th>\n",
       "      <th>LogReg-1</th>\n",
       "      <th>LogReg-0.5</th>\n",
       "      <th>ExTrees</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>BernoulliNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CleanCountVec</th>\n",
       "      <td>0.374430</td>\n",
       "      <td>0.389494</td>\n",
       "      <td>0.520380</td>\n",
       "      <td>0.527880</td>\n",
       "      <td>0.537911</td>\n",
       "      <td>0.545443</td>\n",
       "      <td>0.590538</td>\n",
       "      <td>0.583070</td>\n",
       "      <td>0.515158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyCountVec</th>\n",
       "      <td>0.354367</td>\n",
       "      <td>0.399589</td>\n",
       "      <td>0.525380</td>\n",
       "      <td>0.530380</td>\n",
       "      <td>0.535380</td>\n",
       "      <td>0.532911</td>\n",
       "      <td>0.590538</td>\n",
       "      <td>0.557911</td>\n",
       "      <td>0.510158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanTfIdf</th>\n",
       "      <td>0.527975</td>\n",
       "      <td>0.557975</td>\n",
       "      <td>0.578038</td>\n",
       "      <td>0.577975</td>\n",
       "      <td>0.515127</td>\n",
       "      <td>0.467468</td>\n",
       "      <td>0.570475</td>\n",
       "      <td>0.565443</td>\n",
       "      <td>0.515158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyTfIdf</th>\n",
       "      <td>0.535538</td>\n",
       "      <td>0.550443</td>\n",
       "      <td>0.575601</td>\n",
       "      <td>0.580506</td>\n",
       "      <td>0.505095</td>\n",
       "      <td>0.464968</td>\n",
       "      <td>0.577975</td>\n",
       "      <td>0.547880</td>\n",
       "      <td>0.510158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanW2V</th>\n",
       "      <td>0.118133</td>\n",
       "      <td>0.108133</td>\n",
       "      <td>0.206044</td>\n",
       "      <td>0.203544</td>\n",
       "      <td>0.201044</td>\n",
       "      <td>0.198544</td>\n",
       "      <td>0.183481</td>\n",
       "      <td>0.208608</td>\n",
       "      <td>0.198513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyW2V</th>\n",
       "      <td>0.299051</td>\n",
       "      <td>0.309241</td>\n",
       "      <td>0.198513</td>\n",
       "      <td>0.198513</td>\n",
       "      <td>0.198513</td>\n",
       "      <td>0.198513</td>\n",
       "      <td>0.344367</td>\n",
       "      <td>0.354367</td>\n",
       "      <td>0.314177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanSpaCy</th>\n",
       "      <td>0.480032</td>\n",
       "      <td>0.507627</td>\n",
       "      <td>0.582911</td>\n",
       "      <td>0.590443</td>\n",
       "      <td>0.547880</td>\n",
       "      <td>0.520190</td>\n",
       "      <td>0.525285</td>\n",
       "      <td>0.527785</td>\n",
       "      <td>0.512627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtySpaCy</th>\n",
       "      <td>0.492532</td>\n",
       "      <td>0.537848</td>\n",
       "      <td>0.577943</td>\n",
       "      <td>0.590570</td>\n",
       "      <td>0.555443</td>\n",
       "      <td>0.517722</td>\n",
       "      <td>0.525348</td>\n",
       "      <td>0.520253</td>\n",
       "      <td>0.502532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  KNN-5    KNN-10     SVC-1   SVC-0.5  LogReg-1  LogReg-0.5  \\\n",
       "CleanCountVec  0.374430  0.389494  0.520380  0.527880  0.537911    0.545443   \n",
       "DirtyCountVec  0.354367  0.399589  0.525380  0.530380  0.535380    0.532911   \n",
       "CleanTfIdf     0.527975  0.557975  0.578038  0.577975  0.515127    0.467468   \n",
       "DirtyTfIdf     0.535538  0.550443  0.575601  0.580506  0.505095    0.464968   \n",
       "CleanW2V       0.118133  0.108133  0.206044  0.203544  0.201044    0.198544   \n",
       "DirtyW2V       0.299051  0.309241  0.198513  0.198513  0.198513    0.198513   \n",
       "CleanSpaCy     0.480032  0.507627  0.582911  0.590443  0.547880    0.520190   \n",
       "DirtySpaCy     0.492532  0.537848  0.577943  0.590570  0.555443    0.517722   \n",
       "\n",
       "                ExTrees  RandomForest  BernoulliNB  \n",
       "CleanCountVec  0.590538      0.583070     0.515158  \n",
       "DirtyCountVec  0.590538      0.557911     0.510158  \n",
       "CleanTfIdf     0.570475      0.565443     0.515158  \n",
       "DirtyTfIdf     0.577975      0.547880     0.510158  \n",
       "CleanW2V       0.183481      0.208608     0.198513  \n",
       "DirtyW2V       0.344367      0.354367     0.314177  \n",
       "CleanSpaCy     0.525285      0.527785     0.512627  \n",
       "DirtySpaCy     0.525348      0.520253     0.502532  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN-5</th>\n",
       "      <th>KNN-10</th>\n",
       "      <th>SVC-1</th>\n",
       "      <th>SVC-0.5</th>\n",
       "      <th>LogReg-1</th>\n",
       "      <th>LogReg-0.5</th>\n",
       "      <th>ExTrees</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>BernoulliNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CleanCountVec</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyCountVec</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanTfIdf</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyTfIdf</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanW2V</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtyW2V</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CleanSpaCy</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirtySpaCy</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               KNN-5  KNN-10  SVC-1  SVC-0.5  LogReg-1  LogReg-0.5  ExTrees  \\\n",
       "CleanCountVec    0.1     0.0    0.1      0.1       1.2         1.4      2.7   \n",
       "DirtyCountVec    0.0     0.0    0.1      0.1       1.3         1.1      2.7   \n",
       "CleanTfIdf       0.0     0.0    0.1      0.1       0.6         0.5      2.8   \n",
       "DirtyTfIdf       0.1     0.1    0.1      0.1       0.6         0.5      2.8   \n",
       "CleanW2V         0.1     0.1    1.7      0.9       0.7         0.4      3.1   \n",
       "DirtyW2V         0.2     0.3    1.1      0.6       0.2         0.3      2.8   \n",
       "CleanSpaCy       0.2     0.3    4.4      2.5       2.9         2.7      3.0   \n",
       "DirtySpaCy       0.2     0.2    3.9      2.5       2.9         2.1      3.1   \n",
       "\n",
       "               RandomForest  BernoulliNB  \n",
       "CleanCountVec           3.2          0.0  \n",
       "DirtyCountVec           3.0          0.0  \n",
       "CleanTfIdf              3.3          0.0  \n",
       "DirtyTfIdf              3.0          0.0  \n",
       "CleanW2V                6.6          0.0  \n",
       "DirtyW2V                5.9          0.1  \n",
       "CleanSpaCy              5.8          0.0  \n",
       "DirtySpaCy              5.9          0.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning to Find Best Model\n",
    "The best scoring model was the Linear SVM model. Based on the initial findings, it looks like C < 1 would be the ideal regularization parameter, but we can do a search to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(max_iter=2500)\n",
    "params = {'loss': ['hinge','squared_hinge'],\n",
    "          'C': [0.25,0.5,0.75,1,1.25,1.5]}\n",
    "grid_search = GridSearchCV(model,params,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msh50\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=2500,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],\n",
       "                         'loss': ['hinge', 'squared_hinge']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(dirt_mat,y)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=2500,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params2 = {'C':[0.3,0.4,0.5,0.6,0.7]}\n",
    "grid_search2 = GridSearchCV(model,params2,'accuracy')\n",
    "grid_search2.fit(dirt_mat,y)\n",
    "grid_search2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(max_iter=2500)\n",
    "params3 = {'C':[0.43,0.47,0.5,0.53,0.57]}\n",
    "grid_search3 = GridSearchCV(model,params3,'accuracy')\n",
    "grid_search3.fit(dirt_mat,y)\n",
    "bestsvc = grid_search3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7912707717395134"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bestsvc, dirt_mat, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1500)\n",
    "params = {'C': [1,2,3,4,5,6,7,8]}\n",
    "grid_search = GridSearchCV(model,params,'accuracy')\n",
    "grid_search.fit(dirt_mat,y)\n",
    "bestlogreg = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.791295928964266"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bestlogreg, dirt_mat, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 36s\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "params = {'n_neighbors': [11,12,13,14,15,16,17,18,19]}\n",
    "grid_search = GridSearchCV(model,params,'accuracy')\n",
    "%time grid_search.fit(dirt_mat,y)\n",
    "bestknn = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744632156584838"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bestknn, dirt_mat, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Classifier\n",
    "Now we'll try to see if using a voting classifier with some of our better models will increase the accuracy score.\n",
    "\n",
    "Since LinearSVC doesn't have a predict_proba() fucntion, we'll need to wrap it in a CalibratedClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestsvc=CalibratedClassifierCV(base_estimator=LinearSVC(C=0.53,max_iter=2500), method='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = VotingClassifier(estimators=[('svc',bestsvc),('logreg',bestlogreg),('knn',bestknn)],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7977825197588838"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time cross_val_score(vote,dirt_mat,y,cv=5,scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the accuracy is marginally improved, but still not over the 0.8 hump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit881a291f7fc24b5187080a12abc1d62b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
